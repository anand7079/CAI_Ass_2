{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.docstore.document import Document\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\root\\opt\\workspace\\langchain\\cai_assignment_2\\.venvcai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\root\\opt\\workspace\\langchain\\cai_assignment_2\\.venvcai\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\root\\opt\\workspace\\langchain\\cai_assignment_2\\.venvcai\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing Chroma database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umesh.Pandey\\AppData\\Local\\Temp\\ipykernel_33460\\3428916624.py:64: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
      "C:\\Users\\Umesh.Pandey\\AppData\\Local\\Temp\\ipykernel_33460\\3428916624.py:80: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def read_pdfs(pdf_directory: str) -> List[dict]:\n",
    "    \"\"\"Reads all PDFs from a directory and returns a list of documents with text and metadata.\"\"\"\n",
    "    all_documents = []\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filepath = os.path.join(pdf_directory, filename)\n",
    "            try:\n",
    "                loader = PyMuPDFLoader(filepath)\n",
    "                documents = loader.load()\n",
    "                for doc in documents:\n",
    "                    # Ensure metadata has 'source'\n",
    "                    if 'source' not in doc.metadata:\n",
    "                        doc.metadata[\"source\"] = filename\n",
    "                    all_documents.append({\"text\": doc.page_content, \"metadata\": doc.metadata})\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    return all_documents\n",
    "\n",
    "def chunk_text(documents: List[dict], chunk_size: int = 100, chunk_overlap: int = 0) -> List[dict]:\n",
    "    \"\"\"Splits a list of documents into chunks with metadata.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    all_chunks = []\n",
    "    for document in documents:\n",
    "        chunks = text_splitter.split_text(document[\"text\"])\n",
    "        for chunk in chunks:\n",
    "            all_chunks.append({\"text\": chunk, \"metadata\": document[\"metadata\"]})\n",
    "    return all_chunks\n",
    "\n",
    "def store_chunks_in_chroma(chunks: List[dict], embeddings, persist_directory: str = \"db\"):\n",
    "    \"\"\"Stores text chunks with metadata in Chroma vector database.\"\"\"\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    metadatas = [chunk[\"metadata\"] for chunk in chunks]\n",
    "    vectordb = Chroma.from_texts(texts, embeddings, metadatas=metadatas, persist_directory=persist_directory)\n",
    "    return vectordb\n",
    "\n",
    "def create_bm25_index(chunks: List[dict]) -> BM25Retriever:\n",
    "    \"\"\"Creates a BM25 index from document chunks.\"\"\"\n",
    "    # Convert chunk dictionaries to Document objects\n",
    "    documents = [\n",
    "        Document(page_content=chunk[\"text\"], metadata=chunk[\"metadata\"])\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    \n",
    "    # Tokenize document page_content for BM25\n",
    "    tokenized_docs = [doc.page_content.split() for doc in documents]\n",
    "    bm25_index = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # Wrap the BM25 index in a LangChain-compatible retriever using the correct keyword\n",
    "    bm25_retriever = BM25Retriever(vectorizer=bm25_index, docs=documents)\n",
    "    return bm25_retriever\n",
    "\n",
    "# --- Main execution ---\n",
    "pdf_dir = \"data/docs\"  # Path to your PDF directory\n",
    "persist_dir = \"db\"     # Directory to store Chroma DB\n",
    "\n",
    "# 1. Read PDFs and create chunks (do this once)\n",
    "pdf_documents = read_pdfs(pdf_dir)\n",
    "chunks = chunk_text(pdf_documents, chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# 2. Load or create the Chroma vector store using the same chunks\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "if os.path.exists(persist_dir) and os.listdir(persist_dir):\n",
    "    print(\"Loading existing Chroma database...\")\n",
    "    vectordb = Chroma(persist_directory=persist_dir, embedding_function=embeddings)\n",
    "else:\n",
    "    print(\"Chroma database not found. Processing PDFs...\")\n",
    "    vectordb = store_chunks_in_chroma(chunks, embeddings, persist_dir)\n",
    "\n",
    "# 3. Create BM25 index from the already created chunks (used for keyword search)\n",
    "bm25_retriever = create_bm25_index(chunks)\n",
    "\n",
    "# 4. Initialize language model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0.7,\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# 5. Initialize conversation memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key='answer'\n",
    ")\n",
    "\n",
    "# 6. Create an ensemble retriever combining vector DB and BM25 retrievers\n",
    "vector_retriever = vectordb.as_retriever()\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vector_retriever, bm25_retriever],\n",
    "    weights=[0.6, 0.4]  # Adjust weights based on your use case\n",
    ")\n",
    "\n",
    "# 7. Create conversation chain with memory and ensemble retriever\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=ensemble_retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What is the main topic of the document?\n",
      "Answer: The main topic of the document appears to be \"Adapting existing practices for handling datasets and models in machine learning (ML)\" specifically in the context of COVID-19 pandemic, as it mentions projects like Data Version Control (DVC) and model cards. However, the broader theme seems to be about developing approaches to handle datasets and models in a coherent and reliable way across different types of artifacts.\n",
      "\n",
      "Sources:\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 25)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 19)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 1)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 19)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 11)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 12)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 8)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 22)\n",
      "\n",
      "Question: Can you summarize the key points?\n",
      "Answer: You asked about adapting existing practices for handling datasets and models in machine learning, specifically in the context of COVID-19 pandemic projects.\n",
      "\n",
      "Sources:\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 19)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 16)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 11)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 18)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 20)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 12)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 8)\n",
      "\n",
      "Question: What references are cited in this context?\n",
      "Answer: The sources cited to support the discussion on adapting existing practices for handling datasets and models in machine learning, particularly in the context of COVID-19 pandemic projects, were:\n",
      "\n",
      "1. Lawrence [150]\n",
      "2. Royal Society DELVE\n",
      "3. Mutembesa et al. [110]\n",
      "4. Daniel Mutembesa, Christopher Omongo, and Ernest Mwebaze. Crowdsourcing real-time viral disease and pest information: A case of nation-wide cassava disease surveillance in a developing country.\n",
      "5. Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable\n",
      "6. Dang et al. [69]\n",
      "7. Dang et al. [74]\n",
      "8. Mutembesa et al. [110]\n",
      "\n",
      "Sources:\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 19)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 16)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 11)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 26)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 10)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 12)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 13)\n"
     ]
    }
   ],
   "source": [
    "# 8. Example conversation sequence\n",
    "questions = [\n",
    "    \"What is the main topic of the document?\",\n",
    "    \"Can you summarize the key points?\",\n",
    "    \"What references are cited in this context?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"\\nQuestion: {result['question']}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    \n",
    "    # Safely access source documents metadata\n",
    "    print(\"\\nSources:\")\n",
    "    for doc in result['source_documents']:\n",
    "        source = doc.metadata.get('source', 'Unknown source')\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        print(f\"- {source} (page {page})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI interface for user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: what is mlops\n",
      "\n",
      "ANSWER: ML-Ops (Machine Learning Operations) refers to the practices and procedures involved in building, deploying, managing, and maintaining machine learning models in production environments. This includes activities such as data collection, model training, deployment, monitoring, and troubleshooting.\n",
      "\n",
      "Reference Documents:\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 10)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 10)\n",
      "- data/docs\\Challenges in Deploying Machine Learning - a Survey of Case Studies.pdf (page 21)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"\\nYour question (type 'exit' to quit): \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        break\n",
    "    result = qa_chain.invoke({\"question\": user_input})\n",
    "    print(f\"\\nQuestion: {result['question']}\")\n",
    "    print(f\"\\nANSWER: {result['answer']}\")\n",
    "    \n",
    "    if result['source_documents']:\n",
    "        print(\"\\nReference Documents:\")\n",
    "        for doc in result['source_documents'][:3]: \n",
    "            source = doc.metadata.get('source', 'Unknown source')\n",
    "            page = doc.metadata.get('page', 'N/A')\n",
    "            print(f\"- {source} (page {page})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvcai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
